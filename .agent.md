# MySQL Downloads Scraper Project

## Project Overview

This is a Python web scraping project that extracts MySQL Community Server download information from the official MySQL archives website. The scraper collects download links, versions, and metadata for different operating systems and saves the data to a structured JSON database.

### Key Technologies
- **Language**: Python 3.x
- **Web Scraping**: BeautifulSoup4, httpx
- **Concurrency**: ThreadPoolExecutor for parallel requests
- **Progress Tracking**: tqdm for progress bars
- **Logging**: Python logging module

## Important Files and Structure

### Core Files
- `mysql.py` - Main scraper implementation with MysqlScrape class
- `database.json` - Output JSON file containing scraped MySQL download data
- `requirements.txt` - Python dependencies
- `logs.txt` - Runtime logs (excluded from git via .gitignore)
- `.gitignore` - Git ignore rules (excludes .venv and logs.txt)
- `test.txt` - Sample HTML content from MySQL downloads page

### Key Classes and Methods
- `MysqlScrape` - Main scraper class
  - `scrape_base()` - Static method to parse download tables from HTML
  - `get_mysql_older()` - Method to fetch older MySQL versions with concurrency

## Development Guidelines

### Code Structure
- Use static methods where class state is not needed
- Implement concurrent processing with ThreadPoolExecutor (max 8 workers)
- Include comprehensive logging with real-time file flushing
- Use progress bars for long-running operations

### Data Handling
- Filter out unwanted package types (32-bit, test, minimal, debug versions)
- Exclude pre-release versions (rc, alpha, beta, snapshot, dmr)
- Prefer specific file formats per OS:
  - Windows: .zip files (exclude .msi)
  - Linux: exclude .tar.gz files
  - macOS: exclude .dmg files

### Supported Configurations
- **MySQL Versions**: 8.2, 8.1, 8.0, 5.7, 5.6, 5.5
- **Operating Systems**: Windows (win), Linux (linux), macOS (mac)
- **OS ID Mapping**: win=3, linux=2, mac=33 (for MySQL download URLs)

### Error Handling
- Graceful handling of missing GPG signatures
- Comprehensive exception logging
- Continue processing other versions if one fails

### Output Format
- JSON structure with OS-grouped data
- Version sorting (descending order)
- Metadata includes: version, GPG signature, download link
- One entry per version per OS (deduplicated)

## Best Practices

### Performance
- Use concurrent requests (8 max workers) to speed up scraping
- Implement progress tracking for user feedback
- Log all operations for debugging and monitoring

### Data Quality
- Validate URLs and extract OS information from query parameters
- Filter out development/test packages automatically
- Ensure consistent data structure across all entries

### Maintenance
- Regular updates may be needed if MySQL changes their website structure
- Monitor logs for scraping errors or missing data
- Update version filters as new MySQL versions are released

### Dependencies Management
- Keep requirements.txt updated with exact versions
- Use virtual environments (.venv) for isolation
- Pin dependency versions for reproducible builds

## Running the Project

### Setup
```bash
pip install -r requirements.txt
```

### Execution
```bash
python mysql.py
```

### Output
- Creates/updates `database.json` with scraped data
- Generates `logs.txt` with detailed operation logs
- Progress bars show real-time scraping status

## Troubleshooting

### Common Issues
- Network timeouts: Adjust httpx timeout settings if needed
- Missing GPG signatures: Check MySQL website changes
- Version parsing errors: Update regex patterns for new version formats
- Blocked requests: Implement rate limiting if needed

### Debugging
- Check `logs.txt` for detailed error information
- Verify URL patterns match current MySQL website structure
- Test individual version scraping before full runs